# GPU Shader Implementation - Technical Deep Dive

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CPU (JavaScript)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Load textures (once)                                 â”‚
â”‚  â€¢ Create geometry with baseUV (once)                   â”‚
â”‚  â€¢ Create shader material (once)                        â”‚
â”‚  â€¢ Update time uniform (per frame)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GPU (GLSL Shaders)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  VERTEX SHADER (runs per particle in parallel):         â”‚
â”‚    1. Read baseUV attribute                             â”‚
â”‚    2. Calculate noise offset                            â”‚
â”‚    3. Apply offset to UV                                â”‚
â”‚    4. texture2D(depthTexture, uv) â†’ depth               â”‚
â”‚    5. texture2D(colorTexture, uv) â†’ color               â”‚
â”‚    6. Calculate 3D position from (UV + depth)           â”‚
â”‚    7. Output position & color                           â”‚
â”‚                                                          â”‚
â”‚  FRAGMENT SHADER (runs per visible pixel):              â”‚
â”‚    1. Check if inside circle                            â”‚
â”‚    2. Apply emissive multiplier                         â”‚
â”‚    3. Output final color                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Shader Code Breakdown

### Vertex Shader

```glsl
attribute vec2 baseUV;  // Input: base UV coordinates for this particle
uniform sampler2D colorTexture;  // Input: color image texture
uniform sampler2D depthTexture;  // Input: depth map texture
uniform float time;  // Input: current time for animation
varying vec3 vColor;  // Output: color to fragment shader

void main() {
  vec2 uv = baseUV;  // Start with base UV
  
  // === ANIMATION SECTION ===
  if (animateParticles > 0.5) {
    float t = time * animationSpeed * 0.5;
    
    if (useNoiseType > 0.5) {
      // Curl noise: divergence-free flow
      vec3 curl = curlNoise(vec3(uv * 3.0, t));
      vec2 offset = curl.xy * noiseIntensity;
    } else {
      // Perlin noise: smooth organic movement
      float noiseX = perlinNoise(vec3(uv * 3.0, t));
      float noiseY = perlinNoise(vec3(uv * 3.0 + vec2(100.0), t));
      vec2 offset = vec2(noiseX, noiseY) * noiseIntensity;
    }
    
    uv = clamp(uv + offset, 0.0, 1.0);  // Keep in [0,1]
  }
  
  // === TEXTURE SAMPLING ===
  float depth = texture2D(depthTexture, uv).r;  // Sample depth
  vColor = texture2D(colorTexture, uv).rgb;      // Sample color
  
  // === POSITION CALCULATION ===
  vec3 pos;
  pos.x = (uv.x - 0.5) * aspect;  // X: UV to world space
  pos.y = (uv.y - 0.5) * -1.0;    // Y: UV to world space (flipped)
  pos.z = depth * displacementScale;  // Z: from depth map
  
  // === SCREEN PROJECTION ===
  vec4 mvPosition = modelViewMatrix * vec4(pos, 1.0);
  gl_PointSize = particleSize * screenScale / -mvPosition.z;  // Perspective
  gl_Position = projectionMatrix * mvPosition;
}
```

### Fragment Shader

```glsl
varying vec3 vColor;  // Input: color from vertex shader

void main() {
  // === CIRCLE SHAPE ===
  float distanceToCenter = distance(gl_PointCoord, vec2(0.5));
  if (distanceToCenter > 0.5) discard;  // Discard pixels outside circle
  
  // === EMISSIVE GLOW ===
  vec3 emissiveColor = vColor * 1.5;  // Brighten for bloom effect
  gl_FragColor = vec4(emissiveColor, 0.8);  // Output with transparency
}
```

## Noise Functions in GLSL

### Perlin Noise

Based on Ken Perlin's improved noise algorithm:
- **Input**: 3D coordinate (x, y, z where z = time)
- **Output**: Smooth continuous value [-1, 1]
- **Characteristics**: Organic, band-limited, deterministic

```glsl
float perlinNoise(vec3 v) {
  // 1. Find unit cube containing point
  vec3 i = floor(v);
  
  // 2. Find relative position in cube
  vec3 f = fract(v);
  
  // 3. Compute fade curves
  vec3 u = smoothstep(0.0, 1.0, f);
  
  // 4. Hash coordinates of cube corners
  // 5. Interpolate between gradients
  // 6. Return smooth noise value
}
```

### Curl Noise

Calculates curl (âˆ‡Ã—) of a potential field:
- **Input**: 3D coordinate
- **Output**: Divergence-free 3D vector
- **Characteristics**: Swirling, fluid-like, no sinks/sources

```glsl
vec3 curlNoise(vec3 p) {
  float eps = 0.01;
  
  // Sample potential field around point
  float n1 = perlinNoise(vec3(p.x, p.y + eps, p.z));
  float n2 = perlinNoise(vec3(p.x, p.y - eps, p.z));
  // ... (6 samples total)
  
  // Calculate curl: (âˆ‚P/âˆ‚z - âˆ‚P/âˆ‚y, âˆ‚P/âˆ‚x - âˆ‚P/âˆ‚z, âˆ‚P/âˆ‚y - âˆ‚P/âˆ‚x)
  float x = (n1 - n2) / (2.0 * eps) - (n3 - n4) / (2.0 * eps);
  float y = (n5 - n6) / (2.0 * eps) - (n1 - n2) / (2.0 * eps);
  float z = (n3 - n4) / (2.0 * eps) - (n5 - n6) / (2.0 * eps);
  
  return vec3(x, y, z);
}
```

## Uniform Management

### Static Uniforms (set once):
```typescript
uniforms: {
  colorTexture: { value: colorTex },     // Texture pointer
  depthTexture: { value: dispTex },      // Texture pointer
  particleSize: { value: particleSize }, // Point size
  screenScale: { value: window.innerHeight / 2 },
  aspect: { value: aspect }              // Image aspect ratio
}
```

### Dynamic Uniforms (updated per frame):
```typescript
useFrame(({ clock }) => {
  material.uniforms.time.value = clock.getElapsedTime()
  material.uniforms.displacementScale.value = displacementScale
  material.uniforms.animateParticles.value = animateParticles ? 1.0 : 0.0
  material.uniforms.animationSpeed.value = animationSpeed
  material.uniforms.noiseIntensity.value = noiseIntensity
  material.uniforms.useNoiseType.value = noiseType === 'curl' ? 1.0 : 0.0
})
```

**Cost per frame**: ~6 float updates = negligible!

## GPU Parallelism

### How GPU Processes Particles:

```
CPU sends: "Here's time = 5.23, process all particles"

GPU divides work into warps/wavefronts:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Warp 1: Particles 0-31    (parallel)  â”‚
â”‚ Warp 2: Particles 32-63   (parallel)  â”‚
â”‚ Warp 3: Particles 64-95   (parallel)  â”‚
â”‚ ...                                    â”‚
â”‚ Warp N: Particles 65504-65535 (parallel) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Each warp executes in lockstep:
- All 32 threads run same instruction
- Texture cache shared within warp
- Result: ALL particles done in ~1ms
```

### GPU Cores Utilization:

Example GPU (NVIDIA RTX 3060):
- **CUDA Cores**: 3584
- **Texture Units**: 112
- **Memory Bandwidth**: 360 GB/s

For 65,536 particles:
- Each core handles ~18 particles
- Processes in <20 shader cycles
- Texture cache minimizes memory access
- Result: Sub-millisecond execution

## Memory Layout

### Geometry Buffer (CPU â†’ GPU once):
```
baseUV attribute: Float32Array(particleCount Ã— 2)
[u0, v0, u1, v1, u2, v2, ...]

Example for 256Ã—256 = 65,536 particles:
Size: 65,536 Ã— 2 Ã— 4 bytes = 524 KB
Transfer: Once at startup
```

### Texture Memory (GPU resident):
```
Color Texture: width Ã— height Ã— 4 bytes (RGBA)
Depth Texture: width Ã— height Ã— 4 bytes (RGBA, uses R channel)

Example for 1920Ã—1080 image:
Color: 1920 Ã— 1080 Ã— 4 = 8.3 MB
Depth: 1920 Ã— 1080 Ã— 4 = 8.3 MB
Total: 16.6 MB (stays on GPU)
```

## Optimization Techniques Used

### 1. Texture Caching
```typescript
colorTex.minFilter = THREE.LinearFilter
colorTex.magFilter = THREE.LinearFilter
```
- GPU caches recently accessed texels
- Neighboring particles likely share cache lines
- Reduces memory bandwidth

### 2. Conditional Branching Minimized
```glsl
if (animateParticles > 0.5) { ... }
```
- Simple float comparison
- Entire warp takes same branch
- No divergence penalty

### 3. Shader Constant Folding
```glsl
vec3(uv * 3.0, t)  // Compiler optimizes
```
- Constants known at compile time
- GPU driver optimizes instruction sequence

### 4. Additive Blending
```typescript
blending: THREE.AdditiveBlending
```
- GPU hardware accelerated
- No alpha sorting needed
- Framebuffer operations optimized

## Comparison: Buffer Updates

### Old CPU Method:
```typescript
// Per frame, for each particle:
positions[i * 3 + 0] = xPos  // Write to CPU memory
positions[i * 3 + 1] = yPos  // Write to CPU memory
positions[i * 3 + 2] = zPos  // Write to CPU memory
colors[i * 3 + 0] = r        // Write to CPU memory
colors[i * 3 + 1] = g        // Write to CPU memory
colors[i * 3 + 2] = b        // Write to CPU memory

// Then upload entire buffer to GPU:
gl.bufferSubData(positions)  // CPU â†’ GPU transfer
gl.bufferSubData(colors)     // CPU â†’ GPU transfer

Cost: 65,536 particles Ã— 6 floats = 1.5 MB transfer per frame @ 60 FPS = 90 MB/s
```

### New GPU Method:
```typescript
// Per frame:
material.uniforms.time.value = 5.23  // 1 float

Cost: 4 bytes per frame @ 60 FPS = 240 bytes/s
```

**Bandwidth Savings**: 375,000x less data transfer! ğŸš€

## Why This Matters

1. **Responsiveness**
   - UI controls update instantly
   - No lag when adjusting sliders
   - Smooth 60 FPS maintained

2. **Power Efficiency**
   - CPU free for other tasks
   - GPU designed for parallel workloads
   - Lower overall system power

3. **Scalability**
   - Easy to add more particles
   - GPU scales with hardware
   - Future-proof implementation

4. **Visual Quality**
   - Smooth interpolation via texture filtering
   - No visible quantization
   - Clean particle rendering

---

**Bottom Line**: Moving computation to GPU where it belongs = massive performance win! ğŸ¯
